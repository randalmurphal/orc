version: 2
exported_at: 2026-01-16T23:27:36.907867939-06:00
task:
    id: TASK-371
    title: Verify Board View matches mockup using Playwright
    description: "Use Playwright MCP tools to verify the Board view implementation matches the mockup exactly.\n\nREFERENCE FILES:\n- example_ui/board.html (source HTML/CSS)\n- example_ui/Screenshot_20260116_201804.png (reference screenshot)\n\nVERIFICATION PROCESS:\n1. Start dev server if not running (npm run dev in web/)\n2. Navigate to http://localhost:5173/board using mcp__playwright__browser_navigate\n3. Wait for fonts and data to load\n4. Take accessibility snapshot using mcp__playwright__browser_snapshot\n5. Take visual screenshot using mcp__playwright__browser_take_screenshot\n6. Compare against reference using Read tool on example_ui/Screenshot_20260116_201804.png\n7. Document ALL discrepancies\n\nTEST STRUCTURE TO CREATE:\n```typescript\n// web/e2e/visual/board.spec.ts\nimport { test, expect } from \"../fixtures\";\n\ntest.describe(\"Board View Visual Verification\", () => {\n  test.beforeEach(async ({ page }) => {\n    // Seed test data\n    await page.request.post(\"/api/test/seed\", {\n      data: { runningTasks: 2, queuedTasks: 27, blockedTasks: 1 }\n    });\n    await page.goto(\"/board\");\n    await page.waitForLoadState(\"networkidle\");\n    // Wait for fonts\n    await page.waitForFunction(() => document.fonts.ready);\n  });\n\n  test(\"Icon navigation matches mockup\", async ({ page }) => {\n    const nav = page.locator(\".icon-nav\");\n    await expect(nav).toBeVisible();\n    \n    // Verify dimensions\n    const box = await nav.boundingBox();\n    expect(box?.width).toBe(56);\n    \n    // Verify logo gradient\n    const logo = nav.locator(\".nav-logo\");\n    const bgImage = await logo.evaluate(el => \n      getComputedStyle(el).backgroundImage\n    );\n    expect(bgImage).toContain(\"linear-gradient\");\n    \n    // Verify all nav items present\n    await expect(nav.locator(\".nav-item\")).toHaveCount(7);\n    \n    // Verify active state on Board\n    const boardItem = nav.locator(\"[href=\\\"/board\\\"]\");\n    await expect(boardItem).toHaveClass(/active/);\n  });\n\n  test(\"Top bar matches mockup\", async ({ page }) => {\n    const topBar = page.locator(\".top-bar\");\n    \n    // Verify height\n    const box = await topBar.boundingBox();\n    expect(box?.height).toBe(48);\n    \n    // Verify project selector present\n    await expect(topBar.locator(\".project-selector\")).toBeVisible();\n    \n    // Verify search box\n    await expect(topBar.locator(\".search-box\")).toBeVisible();\n    \n    // Verify session stats\n    await expect(topBar.locator(\".session-stats\")).toBeVisible();\n    await expect(topBar.locator(\".session-stat\")).toHaveCount(3);\n    \n    // Verify action buttons\n    await expect(topBar.locator(\"button:has-text(\\\"Pause All\\\")\")).toBeVisible();\n    await expect(topBar.locator(\"button:has-text(\\\"+ New Task\\\")\")).toBeVisible();\n  });\n\n  test(\"Queue column matches mockup\", async ({ page }) => {\n    const queue = page.locator(\".board-queue\");\n    \n    // Verify swimlane structure\n    await expect(queue.locator(\".swimlane\")).toHaveCount.greaterThan(0);\n    \n    // Verify swimlane headers\n    const swimlane = queue.locator(\".swimlane\").first();\n    await expect(swimlane.locator(\".swimlane-header\")).toBeVisible();\n    await expect(swimlane.locator(\".swimlane-count\")).toBeVisible();\n    \n    // Verify task cards\n    await expect(swimlane.locator(\".task-card\")).toHaveCount.greaterThan(0);\n    \n    // Verify card structure\n    const card = swimlane.locator(\".task-card\").first();\n    await expect(card.locator(\".task-id\")).toBeVisible();\n    await expect(card.locator(\".task-title\")).toBeVisible();\n  });\n\n  test(\"Running column matches mockup\", async ({ page }) => {\n    const running = page.locator(\".board-running\");\n    \n    // Verify 420px width\n    const box = await running.boundingBox();\n    expect(box?.width).toBe(420);\n    \n    // Verify running cards present\n    await expect(running.locator(\".running-card\")).toHaveCount.greaterThan(0);\n    \n    // Verify pipeline visualization\n    const card = running.locator(\".running-card\").first();\n    await expect(card.locator(\".pipeline\")).toBeVisible();\n    await expect(card.locator(\".pipeline-step\")).toHaveCount(5);\n    \n    // Verify output section\n    await expect(card.locator(\".task-output\")).toBeVisible();\n  });\n\n  test(\"Right panel matches mockup\", async ({ page }) => {\n    const panel = page.locator(\".right-panel\");\n    \n    // Verify 300px width\n    const box = await panel.boundingBox();\n    expect(box?.width).toBe(300);\n    \n    // Verify all sections present\n    await expect(panel.locator(\".panel-section\")).toHaveCount(5);\n    \n    // Verify section headers with correct colors\n    await expect(panel.locator(\"text=Blocked\")).toBeVisible();\n    await expect(panel.locator(\"text=Decisions\")).toBeVisible();\n    await expect(panel.locator(\"text=Claude Config\")).toBeVisible();\n    await expect(panel.locator(\"text=Files Changed\")).toBeVisible();\n    await expect(panel.locator(\"text=Completed\")).toBeVisible();\n  });\n\n  test(\"Visual snapshot matches reference\", async ({ page }) => {\n    await expect(page).toHaveScreenshot(\"board-view.png\", {\n      maxDiffPixels: 500,\n      threshold: 0.2,\n    });\n  });\n});\n```\n\nVERIFICATION CHECKLIST:\n- [ ] Icon navigation: 56px width, correct icons, logo gradient, active states\n- [ ] Top bar: 48px height, layout, search box, session stats format, button styles\n- [ ] Queue column: swimlane headers, task card layout, collapse chevrons\n- [ ] Running column: 420px width, card gradient, pipeline steps, output section\n- [ ] Right panel: 300px width, all 5 sections visible, correct colors\n- [ ] Typography: font sizes, weights, families (Inter + JetBrains Mono)\n- [ ] Colors: all CSS custom properties render correctly\n- [ ] Spacing: padding, margins, gaps match mockup\n\nFOR EACH DISCREPANCY FOUND:\n1. Document the element and what is wrong\n2. Show expected value (from mockup) vs actual value\n3. Identify the file and line to fix\n4. Implement the fix\n5. Re-run verification to confirm fix\n\nFILES TO CREATE:\n- web/e2e/visual/board.spec.ts\n\nFILES TO POTENTIALLY MODIFY:\n- web/src/components/board/*.tsx\n- web/src/components/board/*.css\n- web/src/components/layout/*.tsx\n- web/src/styles/tokens.css"
    weight: large
    status: planned
    branch: orc/TASK-371
    queue: active
    priority: critical
    category: test
    initiative_id: INIT-022
    blocked_by:
        - TASK-353
    created_at: 2026-01-16T21:04:05-06:00
    updated_at: 0001-01-01T00:00:00Z
plan:
    version: 1
    task_id: TASK-371
    weight: large
    description: Large task - spec, design, implement, review, test, docs, validate with multi-agent code review
    phases:
        - id: spec
          name: spec
          prompt: |
            Create a specification for this large task:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            Define:
            1. Requirements and scope
            2. Technical approach
            3. Component breakdown (backend, frontend if applicable)
            4. API design (if applicable)
            5. Success criteria with explicit checkboxes
            6. Testing strategy:
               - Unit tests
               - Integration tests
               - E2E tests (using Playwright MCP tools if frontend exists)

            Include clear completion criteria:
            - What code must be written
            - What tests must pass
            - What E2E scenarios must work
            - What documentation must exist

            Keep iterating until the specification is clear and complete.

            When done, output:
            <phase_complete>true</phase_complete>
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: design
          name: design
          prompt: |
            Create architecture and design for:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            **Specification**:
            {{SPEC_CONTENT}}

            Design requirements:
            1. Define components and their responsibilities
            2. Document design decisions with rationale
            3. Assess implementation risks
            4. Define implementation order

            Output a design document with:
            - Component architecture
            - Design decisions table (DD-1, DD-2, etc.)
            - Risk assessment
            - Implementation order

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - spec
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: implement
          name: implement
          prompt: |
            Implement the large task according to the specification and design:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            **Specification**:
            {{SPEC_CONTENT}}

            **Design**:
            {{DESIGN_CONTENT}}

            {{RETRY_CONTEXT}}

            Implementation protocol:
            1. Follow the design's implementation order
            2. Implement all components defined in the spec
            3. Write unit tests alongside code
            4. Run tests frequently: `go test ./... -v -race`
            5. Fix failures before continuing
            6. If frontend exists:
               - Implement all components
               - Add loading/error states
               - Integrate with API

            Keep iterating until:
            - All components implemented
            - All unit tests pass
            - No race conditions

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - design
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: review
          name: review
          prompt: ""
          depends_on:
            - implement
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: test
          name: test
          prompt: |
            Comprehensive testing for:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            ## Unit Tests
            1. Run: `go test ./... -v -race -cover`
            2. Verify coverage > 80%
            3. Fix any failures

            ## Integration Tests
            1. Test component interactions
            2. Test error handling paths
            3. Verify data flows correctly

            ## E2E Tests (If frontend exists - Use Playwright MCP tools)

            Setup:
            - Start backend server
            - Start frontend server

            Test using Playwright MCP:
            1. `mcp__playwright__browser_navigate` to app URL
            2. `mcp__playwright__browser_snapshot` to verify state
            3. `mcp__playwright__browser_click` to interact
            4. `mcp__playwright__browser_type` for input
            5. `mcp__playwright__browser_wait_for` for async operations

            Critical scenarios:
            - Happy path user flow
            - Error handling
            - Edge cases

            Keep iterating until all tests pass.

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - review
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: docs
          name: docs
          prompt: |
            Update documentation for:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            1. Update any relevant documentation files
            2. Ensure CLAUDE.md reflects the changes if applicable
            3. Add/update code comments where needed
            4. Update README if user-facing changes were made

            Keep iterating until documentation is complete.

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - test
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: validate
          name: validate
          prompt: |
            Final validation for:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            ## Validation Checklist

            ### Code
            - [ ] All requirements from spec are met
            - [ ] Unit tests pass: `go test ./... -v -race`
            - [ ] Test coverage > 80%
            - [ ] No race conditions
            - [ ] Code quality acceptable (no debug statements, TODOs)

            ### Integration
            - [ ] Components work together
            - [ ] Error handling is complete
            - [ ] Performance is acceptable

            ### E2E (If frontend - MUST RUN with Playwright MCP)
            - [ ] Main user flows work
            - [ ] Error states handled
            - [ ] UI updates correctly

            ### Documentation
            - [ ] Code is documented where needed
            - [ ] CLAUDE.md updated if necessary
            - [ ] API documented if applicable

            ## Final Verification

            If frontend exists, run E2E verification:
            1. Start all servers
            2. Use Playwright MCP tools to test all features
            3. Verify everything works end-to-end

            Keep iterating until validation passes.

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - docs
          gate:
            type: auto
          checkpoint: true
          status: pending
state:
    task_id: TASK-371
    current_phase: ""
    current_iteration: 0
    status: pending
    started_at: 0001-01-01T00:00:00Z
    updated_at: 0001-01-01T00:00:00Z
    phases: {}
    tokens:
        input_tokens: 0
        output_tokens: 0
        total_tokens: 0
    cost:
        total_cost_usd: 0
