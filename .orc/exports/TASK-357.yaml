version: 2
exported_at: 2026-01-17T22:16:32.258390628-06:00
task:
    id: TASK-357
    title: Create ActivityHeatmap component (GitHub-style)
    description: "Create the ActivityHeatmap component (GitHub-style 16-week contribution grid).\n\nREFERENCE FILES:\n- example_ui/stats.html (.heatmap-container, lines 153-180)\n- example_ui/Screenshot_20260116_201852.png (activity heatmap section)\n\nTYPESCRIPT INTERFACES:\n```typescript\ninterface ActivityHeatmapProps {\n  data: ActivityData[];\n  weeks?: number; // default 16\n  onDayClick?: (date: string, count: number) => void;\n  className?: string;\n}\n\ninterface ActivityData {\n  date: string; // \"2026-01-16\" format\n  count: number;\n}\n\ninterface HeatmapCell {\n  date: string;\n  count: number;\n  level: 0 | 1 | 2 | 3 | 4; // intensity level\n  dayOfWeek: number; // 0-6\n  weekIndex: number;\n}\n\n// Level thresholds\nconst LEVEL_THRESHOLDS = {\n  0: 0,      // No activity\n  1: 1,      // 1-3 tasks\n  2: 4,      // 4-6 tasks\n  3: 7,      // 7-9 tasks\n  4: 10,     // 10+ tasks\n};\n\nexport const ActivityHeatmap: React.FC<ActivityHeatmapProps> = ({ data, weeks = 16 }) => { ... }\n```\n\nSUCCESS CRITERIA:\n1. ActivityHeatmap component at web/src/components/stats/ActivityHeatmap.tsx\n2. Grid of 16 weeks x 7 days (112 cells)\n3. Day labels on left (Mon, Wed, Fri visible)\n4. Month labels on top\n5. Color intensity based on task count (5 levels)\n6. Tooltip on hover showing date and count\n7. Legend showing intensity levels\n8. npm run typecheck exits 0\n\nEXACT CSS VALUES (from mockup):\n```css\n.heatmap-container {\n  display: flex;\n  flex-direction: column;\n  gap: 8px;\n}\n.heatmap-grid {\n  display: grid;\n  grid-template-rows: repeat(7, 1fr);\n  grid-auto-flow: column;\n  gap: 3px;\n}\n.heatmap-cell {\n  width: 12px;\n  height: 12px;\n  border-radius: 2px;\n  cursor: pointer;\n  transition: transform 0.1s ease;\n}\n.heatmap-cell:hover {\n  transform: scale(1.2);\n}\n.heatmap-cell.level-0 { background: var(--bg-surface); }\n.heatmap-cell.level-1 { background: rgba(16, 185, 129, 0.3); }\n.heatmap-cell.level-2 { background: rgba(16, 185, 129, 0.5); }\n.heatmap-cell.level-3 { background: rgba(16, 185, 129, 0.7); }\n.heatmap-cell.level-4 { background: var(--green); }\n.heatmap-legend {\n  display: flex;\n  align-items: center;\n  gap: 4px;\n  font-size: 10px;\n  color: var(--text-muted);\n}\n.day-label {\n  font-size: 9px;\n  color: var(--text-muted);\n  width: 24px;\n}\n.month-label {\n  font-size: 10px;\n  color: var(--text-secondary);\n}\n```\n\nDATA TRANSFORMATION:\n```typescript\nfunction buildHeatmapGrid(data: ActivityData[], weeks: number): HeatmapCell[][] {\n  const today = new Date();\n  const startDate = subWeeks(today, weeks - 1);\n  // Align to Sunday of that week\n  const alignedStart = startOfWeek(startDate);\n  \n  const dataMap = new Map(data.map(d => [d.date, d.count]));\n  const grid: HeatmapCell[][] = [];\n  \n  for (let w = 0; w < weeks; w++) {\n    const week: HeatmapCell[] = [];\n    for (let d = 0; d < 7; d++) {\n      const date = addDays(alignedStart, w * 7 + d);\n      const dateStr = format(date, \"yyyy-MM-dd\");\n      const count = dataMap.get(dateStr) || 0;\n      week.push({\n        date: dateStr,\n        count,\n        level: getLevel(count),\n        dayOfWeek: d,\n        weekIndex: w,\n      });\n    }\n    grid.push(week);\n  }\n  return grid;\n}\n```\n\nAPI INTEGRATION:\n- GET /api/stats/activity?weeks=16 returns ActivityData[]\n- Cache response for 5 minutes\n- Show skeleton while loading\n\nACCESSIBILITY:\n- role=\"img\" with aria-label describing the visualization\n- Each cell has aria-label: \"X tasks on January 16, 2026\"\n- Keyboard navigation: arrow keys move between cells\n- Screen reader describes overall activity pattern\n\nRESPONSIVE:\n- Below 768px: show 8 weeks instead of 16\n- Below 480px: show 4 weeks\n\nEDGE CASES:\n- Handle missing days in data (show as level-0)\n- Future dates are not clickable\n- Handle timezone differences\n- Empty state when no activity data\n\nFILES TO CREATE:\n- web/src/components/stats/ActivityHeatmap.tsx\n- web/src/components/stats/ActivityHeatmap.css"
    weight: large
    status: planned
    branch: orc/TASK-357
    queue: active
    priority: high
    category: feature
    initiative_id: INIT-019
    blocked_by:
        - TASK-335
    created_at: 2026-01-16T21:00:59-06:00
    updated_at: 0001-01-01T00:00:00Z
plan:
    version: 1
    task_id: TASK-357
    weight: large
    description: Large task - spec, design, implement, review, test, docs, validate with multi-agent code review
    phases:
        - id: spec
          name: spec
          prompt: |
            Create a specification for this large task:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            Define:
            1. Requirements and scope
            2. Technical approach
            3. Component breakdown (backend, frontend if applicable)
            4. API design (if applicable)
            5. Success criteria with explicit checkboxes
            6. Testing strategy:
               - Unit tests
               - Integration tests
               - E2E tests (using Playwright MCP tools if frontend exists)

            Include clear completion criteria:
            - What code must be written
            - What tests must pass
            - What E2E scenarios must work
            - What documentation must exist

            Keep iterating until the specification is clear and complete.

            When done, output:
            <phase_complete>true</phase_complete>
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: design
          name: design
          prompt: |
            Create architecture and design for:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            **Specification**:
            {{SPEC_CONTENT}}

            Design requirements:
            1. Define components and their responsibilities
            2. Document design decisions with rationale
            3. Assess implementation risks
            4. Define implementation order

            Output a design document with:
            - Component architecture
            - Design decisions table (DD-1, DD-2, etc.)
            - Risk assessment
            - Implementation order

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - spec
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: implement
          name: implement
          prompt: |
            Implement the large task according to the specification and design:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            **Specification**:
            {{SPEC_CONTENT}}

            **Design**:
            {{DESIGN_CONTENT}}

            {{RETRY_CONTEXT}}

            Implementation protocol:
            1. Follow the design's implementation order
            2. Implement all components defined in the spec
            3. Write unit tests alongside code
            4. Run tests frequently: `go test ./... -v -race`
            5. Fix failures before continuing
            6. If frontend exists:
               - Implement all components
               - Add loading/error states
               - Integrate with API

            Keep iterating until:
            - All components implemented
            - All unit tests pass
            - No race conditions

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - design
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: review
          name: review
          prompt: ""
          depends_on:
            - implement
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: test
          name: test
          prompt: |
            Comprehensive testing for:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            ## Unit Tests
            1. Run: `go test ./... -v -race -cover`
            2. Verify coverage > 80%
            3. Fix any failures

            ## Integration Tests
            1. Test component interactions
            2. Test error handling paths
            3. Verify data flows correctly

            ## E2E Tests (If frontend exists - Use Playwright MCP tools)

            Setup:
            - Start backend server
            - Start frontend server

            Test using Playwright MCP:
            1. `mcp__playwright__browser_navigate` to app URL
            2. `mcp__playwright__browser_snapshot` to verify state
            3. `mcp__playwright__browser_click` to interact
            4. `mcp__playwright__browser_type` for input
            5. `mcp__playwright__browser_wait_for` for async operations

            Critical scenarios:
            - Happy path user flow
            - Error handling
            - Edge cases

            Keep iterating until all tests pass.

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - review
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: docs
          name: docs
          prompt: |
            Update documentation for:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            1. Update any relevant documentation files
            2. Ensure CLAUDE.md reflects the changes if applicable
            3. Add/update code comments where needed
            4. Update README if user-facing changes were made

            Keep iterating until documentation is complete.

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - test
          gate:
            type: auto
          checkpoint: true
          status: pending
        - id: validate
          name: validate
          prompt: |
            Final validation for:

            **Task**: {{TASK_TITLE}}

            **Description**: {{TASK_DESCRIPTION}}

            ## Validation Checklist

            ### Code
            - [ ] All requirements from spec are met
            - [ ] Unit tests pass: `go test ./... -v -race`
            - [ ] Test coverage > 80%
            - [ ] No race conditions
            - [ ] Code quality acceptable (no debug statements, TODOs)

            ### Integration
            - [ ] Components work together
            - [ ] Error handling is complete
            - [ ] Performance is acceptable

            ### E2E (If frontend - MUST RUN with Playwright MCP)
            - [ ] Main user flows work
            - [ ] Error states handled
            - [ ] UI updates correctly

            ### Documentation
            - [ ] Code is documented where needed
            - [ ] CLAUDE.md updated if necessary
            - [ ] API documented if applicable

            ## Final Verification

            If frontend exists, run E2E verification:
            1. Start all servers
            2. Use Playwright MCP tools to test all features
            3. Verify everything works end-to-end

            Keep iterating until validation passes.

            When done, output:
            <phase_complete>true</phase_complete>
          depends_on:
            - docs
          gate:
            type: auto
          checkpoint: true
          status: pending
state:
    task_id: TASK-357
    current_phase: ""
    current_iteration: 0
    status: pending
    started_at: 0001-01-01T00:00:00Z
    updated_at: 0001-01-01T00:00:00Z
    phases: {}
    tokens:
        input_tokens: 0
        output_tokens: 0
        total_tokens: 0
    cost:
        total_cost_usd: 0
